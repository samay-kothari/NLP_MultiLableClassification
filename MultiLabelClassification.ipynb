{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XGj1rHLmzl9C"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aZ06wbDt0SrJ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet('/content/drive/MyDrive/train-00000-of-00001.parquet')\n",
        "df_test = pd.read_parquet('/content/drive/MyDrive/test-00000-of-00001.parquet')\n",
        "df_validate = pd.read_parquet('/content/drive/MyDrive/validation-00000-of-00001.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0khXFwot0bTD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import sklearn.preprocessing as sk_pre\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Date Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "9smR5-L00LRD"
      },
      "outputs": [],
      "source": [
        "# Pre-preprocessing the text, removing the single letter words amd special characters from the text\n",
        "def preprocess_text(sen):\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6x7zks2do0qa"
      },
      "outputs": [],
      "source": [
        "X, y = df.text.values, df.labels.values\n",
        "X = [preprocess_text(''.join(x)) for x in X]\n",
        "X_test, y_test = df_test.text.values, df_test.labels.values\n",
        "X_test = [preprocess_text(''.join(x)) for x in X_test]\n",
        "X_validate, y_validate = df_validate.text.values, df_validate.labels.values\n",
        "X_validate = [preprocess_text(''.join(x)) for x in X_validate]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqS2LunW0b36"
      },
      "outputs": [],
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X)\n",
        "X = tokenizer.texts_to_sequences(X)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_validate = tokenizer.texts_to_sequences(X_validate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xyWujqgqZg4"
      },
      "outputs": [],
      "source": [
        "multi_label = sk_pre.MultiLabelBinarizer()\n",
        "y = multi_label.fit_transform(y)\n",
        "y_test = multi_label.fit_transform(y_test)\n",
        "y_validate = multi_label.fit_transform(y_validate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX2P1GIA2JP5"
      },
      "outputs": [],
      "source": [
        "max_length = 200\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=max_length, padding='post')\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_length, padding='post')\n",
        "X_validate = tf.keras.preprocessing.sequence.pad_sequences(X_validate, maxlen=max_length, padding = 'post')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Traing/Fine-Tune on given domain-specific dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVb43DJuyG6C",
        "outputId": "19b405ec-fffc-4896-e1e8-145c33e0d8b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "282/282 [==============================] - 154s 536ms/step - loss: 0.3348 - accuracy: 0.5131 - val_loss: 0.3533 - val_accuracy: 0.3030\n",
            "Epoch 2/10\n",
            "282/282 [==============================] - 150s 532ms/step - loss: 0.2935 - accuracy: 0.5471 - val_loss: 0.3437 - val_accuracy: 0.3600\n",
            "Epoch 3/10\n",
            "282/282 [==============================] - 144s 511ms/step - loss: 0.2870 - accuracy: 0.5519 - val_loss: 0.3387 - val_accuracy: 0.3630\n",
            "Epoch 4/10\n",
            "282/282 [==============================] - 128s 455ms/step - loss: 0.2746 - accuracy: 0.5701 - val_loss: 0.3262 - val_accuracy: 0.4330\n",
            "Epoch 5/10\n",
            "282/282 [==============================] - 131s 466ms/step - loss: 0.2521 - accuracy: 0.6097 - val_loss: 0.3213 - val_accuracy: 0.4280\n",
            "Epoch 6/10\n",
            "282/282 [==============================] - 124s 440ms/step - loss: 0.2335 - accuracy: 0.6377 - val_loss: 0.3142 - val_accuracy: 0.4560\n",
            "Epoch 7/10\n",
            "282/282 [==============================] - 131s 465ms/step - loss: 0.2242 - accuracy: 0.6328 - val_loss: 0.3111 - val_accuracy: 0.4460\n",
            "Epoch 8/10\n",
            "282/282 [==============================] - 127s 451ms/step - loss: 0.2073 - accuracy: 0.6440 - val_loss: 0.3255 - val_accuracy: 0.4770\n",
            "Epoch 9/10\n",
            "282/282 [==============================] - 138s 490ms/step - loss: 0.1952 - accuracy: 0.6710 - val_loss: 0.3061 - val_accuracy: 0.4900\n",
            "Epoch 10/10\n",
            "282/282 [==============================] - 128s 454ms/step - loss: 0.1817 - accuracy: 0.6877 - val_loss: 0.3102 - val_accuracy: 0.4950\n",
            "32/32 [==============================] - 3s 94ms/step - loss: 0.3297 - accuracy: 0.4670\n",
            "Test Accuracy: 0.46700000762939453\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=max_length),\n",
        "    tf.keras.layers.LSTM(128),\n",
        "    tf.keras.layers.Dense(10, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=10, validation_data=(X_validate, y_validate))\n",
        "\n",
        "# Evaluate the model\n",
        "evaluation = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {evaluation[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay6ebuy2x3Sn"
      },
      "source": [
        "Above we give an example of a LSTM based end to end simple model, which does not include any pre-trained model. This performance can be improved significantly if we use BERT based model since we have large and complex texts that are required to be labelled and BERT excels and capturing contextual information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Incorporating BERT language Model Internally in the system Archictecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-QL1-ENk3P5X"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6X_fot80pwc",
        "outputId": "a1ad3706-2b20-4a9b-8c8e-9f6a0c850373"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMuVt5zUWoI1",
        "outputId": "0780488f-dce7-41db-ef5e-fa803c609856"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "TBA7GiVY0qNH"
      },
      "outputs": [],
      "source": [
        "X = df.text.values\n",
        "X = [preprocess_text(''.join(x)) for x in X]\n",
        "X_test= df_test.text.values\n",
        "X_test = [preprocess_text(''.join(x)) for x in X_test]\n",
        "X_validate = df_validate.text.values\n",
        "X_validate = [preprocess_text(''.join(x)) for x in X_validate]\n",
        "y = df.labels.values\n",
        "y_test = df_test.labels.values\n",
        "y_validate = df_validate.labels.values\n",
        "multi_label = sk_pre.MultiLabelBinarizer()\n",
        "y = multi_label.fit_transform(y)\n",
        "y_test = multi_label.fit_transform(y_test)\n",
        "y_validate = multi_label.fit_transform(y_validate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Qw7QBP6-6OIn"
      },
      "outputs": [],
      "source": [
        "train_encodings = tokenizer(X, truncation=True, padding=True, max_length = 128, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "F1VuhDTGT2Ko"
      },
      "outputs": [],
      "source": [
        "test_encodings = tokenizer(X_test, truncation=True, padding=True, max_length = 128, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "OpMoi7R18ZKW"
      },
      "outputs": [],
      "source": [
        "y_tensor, y_test_tensor = torch.tensor(y, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "uF3xsrLR8ZfP"
      },
      "outputs": [],
      "source": [
        "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], y_tensor)\n",
        "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size = 2, shuffle = True)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 2, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV1acHWOW2jA",
        "outputId": "d8bda011-a794-4b49-fa6b-f4ef6b5d2d57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "PlOM2g6U-GUa"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piNoCvf2_jUl",
        "outputId": "7fc23550-bab0-4bf5-fc34-a3bd0b7fb062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      0.57      0.68        76\n",
            "           2       0.64      0.70      0.67       234\n",
            "           3       0.74      0.44      0.55       196\n",
            "           4       0.65      0.63      0.64       394\n",
            "           5       0.78      0.34      0.47       188\n",
            "           6       1.00      0.18      0.31        11\n",
            "           7       0.74      0.76      0.75       106\n",
            "           8       0.57      0.53      0.55        43\n",
            "           9       0.57      0.12      0.21        32\n",
            "          10       0.75      0.75      0.75       155\n",
            "\n",
            "   micro avg       0.69      0.58      0.63      1435\n",
            "   macro avg       0.73      0.50      0.56      1435\n",
            "weighted avg       0.70      0.58      0.62      1435\n",
            " samples avg       0.68      0.62      0.62      1435\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids, attention_mask, labels = batch\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.sigmoid(logits).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Convert probabilities to binary predictions\n",
        "threshold = 0.5\n",
        "binary_preds = (np.array(all_preds) > threshold).astype(int)\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(all_labels, binary_preds, target_names=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating the effectiveness of fine tuning handling domains specific NLP Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk-vJK95cajh"
      },
      "source": [
        "\n",
        "1. Here we are encoroporating a model internally, the model (BertForSequenceClassification) is pre-trained on a generic language modeling objective, and then it's fine-tuned for a multi-label text classification task using a dataset specific to our domain.\n",
        "2. As we can see, using a BERT model have the micro avg f1-score of 0.63. and macro average score of 0.56, which is a better performance then end-to-end classification model using LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8NUKbBwzp0u"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
